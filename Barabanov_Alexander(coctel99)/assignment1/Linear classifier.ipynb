{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Задание 1.2 - Линейный классификатор (Linear classifier)\n",
    "\n",
    "В этом задании мы реализуем другую модель машинного обучения - линейный классификатор. Линейный классификатор подбирает для каждого класса веса, на которые нужно умножить значение каждого признака и потом сложить вместе.\n",
    "Тот класс, у которого эта сумма больше, и является предсказанием модели.\n",
    "\n",
    "В этом задании вы:\n",
    "- потренируетесь считать градиенты различных многомерных функций\n",
    "- реализуете подсчет градиентов через линейную модель и функцию потерь softmax\n",
    "- реализуете процесс тренировки линейного классификатора\n",
    "- подберете параметры тренировки на практике\n",
    "\n",
    "На всякий случай, еще раз ссылка на туториал по numpy:  \n",
    "http://cs231n.github.io/python-numpy-tutorial/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "from dataset import load_svhn, random_split_train_val\n",
    "from gradient_check import check_gradient\n",
    "from metrics import multiclass_accuracy \n",
    "import linear_classifer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Как всегда, первым делом загружаем данные\n",
    "\n",
    "Мы будем использовать все тот же SVHN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "def prepare_for_linear_classifier(train_X, test_X):\n",
    "    train_flat = train_X.reshape(train_X.shape[0], -1).astype(np.float) / 255.0\n",
    "    test_flat = test_X.reshape(test_X.shape[0], -1).astype(np.float) / 255.0\n",
    "    \n",
    "    # Subtract mean\n",
    "    mean_image = np.mean(train_flat, axis = 0)\n",
    "    train_flat -= mean_image\n",
    "    test_flat -= mean_image\n",
    "    \n",
    "    # Add another channel with ones as a bias term\n",
    "    train_flat_with_ones = np.hstack([train_flat, np.ones((train_X.shape[0], 1))])\n",
    "    test_flat_with_ones = np.hstack([test_flat, np.ones((test_X.shape[0], 1))])    \n",
    "    return train_flat_with_ones, test_flat_with_ones\n",
    "    \n",
    "train_X, train_y, test_X, test_y = load_svhn(\"data\", max_train=10000, max_test=1000)    \n",
    "train_X, test_X = prepare_for_linear_classifier(train_X, test_X)\n",
    "# Split train into train and val\n",
    "train_X, train_y, val_X, val_y = random_split_train_val(train_X, train_y, num_val = 1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Играемся с градиентами!\n",
    "\n",
    "В этом курсе мы будем писать много функций, которые вычисляют градиенты аналитическим методом.\n",
    "\n",
    "Все функции, в которых мы будем вычислять градиенты, будут написаны по одной и той же схеме.  \n",
    "Они будут получать на вход точку, где нужно вычислить значение и градиент функции, а на выходе будут выдавать кортеж (tuple) из двух значений - собственно значения функции в этой точке (всегда одно число) и аналитического значения градиента в той же точке (той же размерности, что и вход).\n",
    "```\n",
    "def f(x):\n",
    "    \"\"\"\n",
    "    Computes function and analytic gradient at x\n",
    "    \n",
    "    x: np array of float, input to the function\n",
    "    \n",
    "    Returns:\n",
    "    value: float, value of the function \n",
    "    grad: np array of float, same shape as x\n",
    "    \"\"\"\n",
    "    ...\n",
    "    \n",
    "    return value, grad\n",
    "```\n",
    "\n",
    "Необходимым инструментом во время реализации кода, вычисляющего градиенты, является функция его проверки. Эта функция вычисляет градиент численным методом и сверяет результат с градиентом, вычисленным аналитическим методом.\n",
    "\n",
    "Мы начнем с того, чтобы реализовать вычисление численного градиента (numeric gradient) в функции `check_gradient` в `gradient_check.py`. Эта функция будет принимать на вход функции формата, заданного выше, использовать значение `value` для вычисления численного градиента и сравнит его с аналитическим - они должны сходиться.\n",
    "\n",
    "Напишите часть функции, которая вычисляет градиент с помощью численной производной для каждой координаты. Для вычисления производной используйте так называемую two-point formula (https://en.wikipedia.org/wiki/Numerical_differentiation):\n",
    "\n",
    "![image](https://wikimedia.org/api/rest_v1/media/math/render/svg/22fc2c0a66c63560a349604f8b6b39221566236d)\n",
    "\n",
    "Все функции приведенные в следующей клетке должны проходить gradient check."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true,
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "Gradient check passed!\nGradient check passed!\nGradient check passed!\n"
     ],
     "output_type": "stream"
    },
    {
     "data": {
      "text/plain": "True"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 4
    }
   ],
   "source": [
    "# TODO: Implement check_gradient function in gradient_check.py\n",
    "# All the functions below should pass the gradient check\n",
    "\n",
    "def square(x):\n",
    "    return float(x*x), 2*x\n",
    "\n",
    "check_gradient(square, np.array([3.0]))\n",
    "\n",
    "def array_sum(x):\n",
    "    assert x.shape == (2,), x.shape\n",
    "    return np.sum(x), np.ones_like(x)\n",
    "\n",
    "check_gradient(array_sum, np.array([3.0, 2.0]))\n",
    "\n",
    "def array_2d_sum(x):\n",
    "    assert x.shape == (2,2)\n",
    "    return np.sum(x), np.ones_like(x)\n",
    "\n",
    "check_gradient(array_2d_sum, np.array([[3.0, 2.0], [1.0, 0.0]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Начинаем писать свои функции, считающие аналитический градиент\n",
    "\n",
    "Теперь реализуем функцию softmax, которая получает на вход оценки для каждого класса и преобразует их в вероятности от 0 до 1:\n",
    "![image](https://wikimedia.org/api/rest_v1/media/math/render/svg/e348290cf48ddbb6e9a6ef4e39363568b67c09d3)\n",
    "\n",
    "**Важно:** Практический аспект вычисления этой функции заключается в том, что в ней учавствует вычисление экспоненты от потенциально очень больших чисел - это может привести к очень большим значениям в числителе и знаменателе за пределами диапазона float.\n",
    "\n",
    "К счастью, у этой проблемы есть простое решение -- перед вычислением softmax вычесть из всех оценок максимальное значение среди всех оценок:\n",
    "```\n",
    "predictions -= np.max(predictions)\n",
    "```\n",
    "(подробнее здесь - http://cs231n.github.io/linear-classify/#softmax, секция `Practical issues: Numeric stability`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "# TODO Implement softmax and cross-entropy for single sample\n",
    "probs = linear_classifer.softmax(np.array([-10, 0, 10]))\n",
    "\n",
    "# Make sure it works for big numbers too!\n",
    "probs = linear_classifer.softmax(np.array([1000, 0, 0]))\n",
    "assert np.isclose(probs[0], 1.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Кроме этого, мы реализуем cross-entropy loss, которую мы будем использовать как функцию ошибки (error function).\n",
    "В общем виде cross-entropy определена следующим образом:\n",
    "![image](https://wikimedia.org/api/rest_v1/media/math/render/svg/0cb6da032ab424eefdca0884cd4113fe578f4293)\n",
    "\n",
    "где x - все классы, p(x) - истинная вероятность принадлежности сэмпла классу x, а q(x) - вероятность принадлежности классу x, предсказанная моделью.  \n",
    "В нашем случае сэмпл принадлежит только одному классу, индекс которого передается функции. Для него p(x) равна 1, а для остальных классов - 0. \n",
    "\n",
    "Это позволяет реализовать функцию проще!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "5.006760443547122"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 6
    }
   ],
   "source": [
    "probs = linear_classifer.softmax(np.array([-5, 0, 5]))\n",
    "linear_classifer.cross_entropy_loss(probs, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "После того как мы реализовали сами функции, мы можем реализовать градиент.\n",
    "\n",
    "Оказывается, что вычисление градиента становится гораздо проще, если объединить эти функции в одну, которая сначала вычисляет вероятности через softmax, а потом использует их для вычисления функции ошибки через cross-entropy loss.\n",
    "\n",
    "Эта функция `softmax_with_cross_entropy` будет возвращает и значение ошибки, и градиент по входным параметрам. Мы проверим корректность реализации с помощью `check_gradient`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "Gradient check passed!\n"
     ],
     "output_type": "stream"
    },
    {
     "data": {
      "text/plain": "True"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 7
    }
   ],
   "source": [
    "# TODO Implement combined function or softmax and cross entropy and produces gradient\n",
    "loss, grad = linear_classifer.softmax_with_cross_entropy(np.array([1, 0, 0]), 1)\n",
    "check_gradient(lambda x: linear_classifer.softmax_with_cross_entropy(x, 1), np.array([1, 0, 0], np.float))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В качестве метода тренировки мы будем использовать стохастический градиентный спуск (stochastic gradient descent или SGD), который работает с батчами сэмплов. \n",
    "\n",
    "Поэтому все наши фукнции будут получать не один пример, а батч, то есть входом будет не вектор из `num_classes` оценок, а матрица размерности `batch_size, num_classes`. Индекс примера в батче всегда будет первым измерением.\n",
    "\n",
    "Следующий шаг - переписать наши функции так, чтобы они поддерживали батчи.\n",
    "\n",
    "Финальное значение функции ошибки должно остаться числом, и оно равно среднему значению ошибки среди всех примеров в батче."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false,
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "Gradient check passed!\nGradients are different at (0, 2). Analytic: -0.32202, Numeric: -0.09980\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "# TODO Extend combined function so it can receive a 2d array with batch of samples\n",
    "np.random.seed(42)\n",
    "# Test batch_size = 1\n",
    "num_classes = 4\n",
    "batch_size = 1\n",
    "predictions = np.random.randint(-1, 3, size=(batch_size, num_classes)).astype(np.float)\n",
    "target_index = np.random.randint(0, num_classes, size=(batch_size, 1)).astype(np.int)\n",
    "check_gradient(lambda x: linear_classifer.softmax_with_cross_entropy(x, target_index), predictions)\n",
    "\n",
    "# Test batch_size = 3\n",
    "num_classes = 4\n",
    "batch_size = 3\n",
    "predictions = np.random.randint(-1, 3, size=(batch_size, num_classes)).astype(np.float)\n",
    "target_index = np.random.randint(0, num_classes, size=(batch_size, 1)).astype(np.int)\n",
    "check_gradient(lambda x: linear_classifer.softmax_with_cross_entropy(x, target_index), predictions)\n",
    "\n",
    "# Make sure maximum subtraction for numberic stability is done separately for every sample in the batch\n",
    "probs = linear_classifer.softmax(np.array([[20,0,0], [1000, 0, 0]]))\n",
    "assert np.all(np.isclose(probs[:, 0], 1.0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Наконец, реализуем сам линейный классификатор!\n",
    "\n",
    "softmax и cross-entropy получают на вход оценки, которые выдает линейный классификатор.\n",
    "\n",
    "Он делает это очень просто: для каждого класса есть набор весов, на которые надо умножить пиксели картинки и сложить. Получившееся число и является оценкой класса, идущей на вход softmax.\n",
    "\n",
    "Таким образом, линейный классификатор можно представить как умножение вектора с пикселями на матрицу W размера `num_features, num_classes`. Такой подход легко расширяется на случай батча векторов с пикселями X размера `batch_size, num_features`:\n",
    "\n",
    "`predictions = X * W`, где `*` - матричное умножение.\n",
    "\n",
    "Реализуйте функцию подсчета линейного классификатора и градиентов по весам `linear_softmax` в файле `linear_classifer.py`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "Gradient check passed!\n"
     ],
     "output_type": "stream"
    },
    {
     "data": {
      "text/plain": "True"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 9
    }
   ],
   "source": [
    "# TODO Implement linear_softmax function that uses softmax with cross-entropy for linear classifier\n",
    "batch_size = 2\n",
    "num_classes = 2\n",
    "num_features = 3\n",
    "np.random.seed(42)\n",
    "W = np.random.randint(-1, 3, size=(num_features, num_classes)).astype(np.float)\n",
    "X = np.random.randint(-1, 3, size=(batch_size, num_features)).astype(np.float)\n",
    "target_index = np.ones(batch_size, dtype=np.int)\n",
    "\n",
    "loss, dW = linear_classifer.linear_softmax(X, W, target_index)\n",
    "check_gradient(lambda w: linear_classifer.linear_softmax(X, w, target_index), W)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### И теперь регуляризация\n",
    "\n",
    "Мы будем использовать L2 regularization для весов как часть общей функции ошибки.\n",
    "\n",
    "Напомним, L2 regularization определяется как\n",
    "\n",
    "l2_reg_loss = regularization_strength * sum<sub>ij</sub> W[i, j]<sup>2</sup>\n",
    "\n",
    "Реализуйте функцию для его вычисления и вычисления соотвествующих градиентов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "Gradient check passed!\n"
     ],
     "output_type": "stream"
    },
    {
     "data": {
      "text/plain": "True"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 10
    }
   ],
   "source": [
    "# TODO Implement l2_regularization function that implements loss for L2 regularization\n",
    "linear_classifer.l2_regularization(W, 0.01)\n",
    "check_gradient(lambda w: linear_classifer.l2_regularization(w, 0.01), W)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Тренировка!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Градиенты в порядке, реализуем процесс тренировки!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false,
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "# TODO: Implement LinearSoftmaxClassifier.fit function\n",
    "classifier = linear_classifer.LinearSoftmaxClassifier()\n",
    "loss_history = classifier.fit(train_X, train_y, epochs=10, learning_rate=1e-3, batch_size=300, reg=1e1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "[<matplotlib.lines.Line2D at 0x104c5dc8>]"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 12
    },
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# let's look at the loss history!\n",
    "plt.plot(loss_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "Accuracy:  0.127\n",
      "Accuracy after training for 100 epochs:  0.121\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "# Let's check how it performs on validation set\n",
    "pred = classifier.predict(val_X)\n",
    "accuracy = multiclass_accuracy(pred, val_y)\n",
    "print(\"Accuracy: \", accuracy)\n",
    "\n",
    "# Now, let's train more and see if it performs better\n",
    "classifier.fit(train_X, train_y, epochs=100, learning_rate=1e-3, batch_size=300, reg=1e1)\n",
    "pred = classifier.predict(val_X)\n",
    "accuracy = multiclass_accuracy(pred, val_y)\n",
    "print(\"Accuracy after training for 100 epochs: \", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Как и раньше, используем кросс-валидацию для подбора гиперпараметтов.\n",
    "\n",
    "В этот раз, чтобы тренировка занимала разумное время, мы будем использовать только одно разделение на тренировочные (training) и проверочные (validation) данные.\n",
    "\n",
    "Теперь нам нужно подобрать не один, а два гиперпараметра! Не ограничивайте себя изначальными значениями в коде.  \n",
    "Добейтесь точности более чем **20%** на проверочных данных (validation data)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "lr: 0.001000 | rs: 0.000100 | res: 0.231000\n",
      "best validation accuracy achieved: 0.231000\nTime required:  61.183499574661255\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "import time\n",
    "time_start = time.time()\n",
    "\n",
    "num_epochs = 40\n",
    "batch_size = 50\n",
    "\n",
    "learning_rates = [1e-3, 1e-4, 1e-5]\n",
    "reg_strengths = [1e-4, 1e-5, 1e-6]\n",
    "\n",
    "best_classifier = None\n",
    "best_val_accuracy = 0\n",
    "\n",
    "# TODO use validation set to find the best hyperparameters\n",
    "# hint: for best results, you might need to try more values for learning rate and regularization strength \n",
    "# than provided initially\n",
    "for l in learning_rates:\n",
    "    for reg in reg_strengths:\n",
    "        clf = linear_classifer.LinearSoftmaxClassifier() \n",
    "        clf.fit(train_X, train_y, epochs=num_epochs, learning_rate=l, batch_size=batch_size, reg=reg)\n",
    "        pred = clf.predict(val_X)\n",
    "        accuracy = multiclass_accuracy(pred, val_y)\n",
    "        if best_val_accuracy < accuracy:\n",
    "            print('lr: %f | rs: %f | res: %f' % (l, reg, accuracy))\n",
    "            best_val_accuracy = accuracy\n",
    "            best_classifier = clf\n",
    "\n",
    "print('best validation accuracy achieved: %f' % best_val_accuracy)\n",
    "print('Time required: ', time.time() - time_start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Какой же точности мы добились на тестовых данных?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "Linear softmax classifier test set accuracy: 0.200000\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "test_pred = best_classifier.predict(test_X)\n",
    "test_accuracy = multiclass_accuracy(test_pred, test_y)\n",
    "print('Linear softmax classifier test set accuracy: %f' % (test_accuracy, ))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}